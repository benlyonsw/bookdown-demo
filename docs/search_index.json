[["index.html", "My Bookdown My Intro", " My Bookdown Ben Lyons 2023-03-01 My Intro This is my example of a bookdown document. "],["apis-and-iteration.html", "Chapter 1 APIs and Iteration 1.1 APIs 1.2 NPS Visitation Data 1.3 Functions 1.4 Functionize API Pulls 1.5 Function Defaults 1.6 Iterations 1.7 For loops 1.8 Mapping", " Chapter 1 APIs and Iteration 1.0.1 Lesson Objectives In this lesson we will download data using an application programming interface (API), create our own functions, and iterate using for loops and map(). To fulfill these objectives we will be utilizing two park visitation data sets from the National Park Service (NPS): NPS-wide visitation data, and park unit-specific visitation data. There are seven exercises in this lesson that must be completed. 1.1 APIs An API is software that acts as an intermediary between an online data warehouse (or server) and its users (or clients). As data scientists, APIs provide us a way to request clean and nicely-formatted data that the server will then send to our local computers, all within our RStudio console! To work with APIs, we will need to use two new packages: httr, which allows us to communicate with the API’s server, and jsonlite, which allows us to work with one of the most common API data formats, JSON. Let’s go ahead and load in our packages for this lesson: library(tidyverse) library(httr) library(jsonlite) 1.2 NPS Visitation Data This week, we will be exploring NPS visitor use data across the NPS system as a whole, and and across specific park units. Like many institutions, NPS has a server that stores all of this information (as well as many other things), and an API for users to be able to access it. To utilize the NPS API in R, we first need to explore its API’s data structure. In almost every case, we use URLs to access specific data from APIs. To find the access URL for NPS visitation data, go to Stats Rest API - Documentation (though not very intuitive, the NPS API calls its visitation data set “Stats”). Listed there you will see that all data associated with the “Stats” data set can be accessed using the base URL https://irmaservices.nps.gov/v3/rest/stats. From there, you can tack on additional html text to access two different data sets: total/{year} and visitation. For starters, let’s try accessing the total/{year}. This data set gives us total monthly visitation across all NPS park units, for a user-selected year: https://irmaservices.nps.gov/v3/rest/stats/total/{YEAR} If you tried accessing that URL, you’ll have noticed it doesn’t take you anywhere. This is because the curly brackets {} signify locations in the URL that need to be updated by the user based on their specific needs. I’m curious about visitor use in my birth year, so let’s tweak the URL to access visitation data from 1992. In R, we can access this data using httr’s GET() function, replacing {YEAR} with 1992. raw_data &lt;- httr::GET(url = &quot;https://irmaservices.nps.gov/v3/rest/stats/total/1992&quot;) # view raw_data # View(raw_data) Viewing the data set as-is, you can see it is not super human-readable. This is because data sent from APIs is typically packaged using JavaScript Object Notation (JSON). To unpack the data, we will first need to use httr’s content() function. In this example, we want the data to be extracted as text, since this is a data table. Moreover, its encoding is listed as UTF-8. The encoding parameter can be found by opening our raw data set in our R console: raw_data # lists &#39;UTF-8&#39; ## Response [https://irmaservices.nps.gov/v3/rest/stats/total/1992] ## Date: 2023-03-01 17:54 ## Status: 200 ## Content-Type: application/json; charset=utf-8 ## Size: 1.42 kB # convert content to text unpacked_data &lt;- httr::content(raw_data, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) Second, we need to transform this string of text, which is still in JSON formatting, into a data frame using jsonlite’s fromJSON(): # parse text from JSON to data frame final_data &lt;- jsonlite::fromJSON(unpacked_data) final_data ## Month NonRecreationVisitors RecreationVisitors UnitCode UnitName Year ## 1 1 6209285 10940618 NA NA 1992 ## 2 2 6010027 11931340 NA NA 1992 ## 3 3 6756902 15369139 NA NA 1992 ## 4 4 7255782 21458739 NA NA 1992 ## 5 5 7690763 26648530 NA NA 1992 ## 6 6 7593227 33284625 NA NA 1992 ## 7 7 8438755 41099305 NA NA 1992 ## 8 8 8056823 38625804 NA NA 1992 ## 9 9 7329755 26438266 NA NA 1992 ## 10 10 7105574 23616057 NA NA 1992 ## 11 11 6507805 14338165 NA NA 1992 ## 12 12 6702698 10943961 NA NA 1992 Hooray, you have now successfully pulled in an online data set using an API!  1.2.1 Exercise #1 Using the code above as a starting point, pull in monthly NPS-wide visitation data for the years 1980, 1999, and 2018. EightiesRaw &lt;- (httr::GET(url = &quot;https://irmaservices.nps.gov/v3/rest/stats/total/1980&quot;)) EightiesUnpacked &lt;- (httr::content(EightiesRaw, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;)) EightiesFinal &lt;- (jsonlite::fromJSON(EightiesUnpacked)) NinetiesRaw &lt;- (httr::GET(url = &quot;https://irmaservices.nps.gov/v3/rest/stats/total/1999&quot;)) NinetiesUnpacked &lt;- (httr::content(NinetiesRaw, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;)) NinetiesFinal &lt;- (jsonlite::fromJSON(NinetiesUnpacked)) TwentyTensRaw &lt;- (httr::GET(url = &quot;https://irmaservices.nps.gov/v3/rest/stats/total/2018&quot;)) TwentyTensUnpacked &lt;- (httr::content(TwentyTensRaw, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;)) TwentyTensFinal &lt;- (jsonlite::fromJSON(TwentyTensUnpacked)) 1.2.2 Exercise #2 Now, let’s explore the second NPS visitation data set, visitation. This call pulls in monthly data for a specific park, across a specific time frame. Use your new API skills to pull in visitation data for Rocky Mountain National Park from 2010 through 2021, based on the API’s URL template. The unit code for Rocky Mountain National Park is ROMO. (Hint: an API URL can have multiple sections that need to be updated by the user.) RomoRaw &lt;- (httr::GET(url = &quot;https://irmaservices.nps.gov/v3/rest/stats/visitation?unitCodes=ROMO&amp;startMonth=1&amp;startYear=2010&amp;endMonth=12&amp;endYear=2021&quot;)) RomoUnpacked &lt;- (httr::content(RomoRaw, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;)) RomoFinal &lt;- (jsonlite::fromJSON(RomoUnpacked)) 1.3 Functions You may find yourself thinking, “Wow, exercise 1 was overkill!” Indeed, you had to run several lines of code that were nearly identical to what was shown upstream; the only thing you needed to change from one year to the next was the year itself. This sort of redundant coding is not good coding practice. Instead of copying and pasting many coding steps over and over again and tweaking just a tiny portion of it, we can write functions that combine many coding steps into just one command. The benefits of reducing redundant code in this way are threefold. As Grolemund &amp; Wickham describe in their book, R for Data Science: It’s easier to see the intent of your code, because your eyes are drawn to what’s different, not what stays the same. It’s easier to respond to changes in requirements. As your needs change, you only need to make changes in one place, rather than remembering to change every place that you copied-and-pasted the code. You’re likely to have fewer bugs because each line of code is used in more places. Functions provide the option of changing just a minor part of the code base from one run to the next. Think of the GET() function in httr: it is a function that has code under-the-hood so that it isn’t necessary to write out the raw code each time we use it. Instead, we call out the function’s name (GET()), and the necessary argument within that function that tweaks the code to fit it to our needs (url = \"&lt;SOME_URL_WE_CHOOSE&gt;\"). 1.4 Functionize API Pulls Let’s try making a function called parkwide_visitation() that pulls in NPS-wide visitation data for a year of choice. To develop a function requires specific formatting: &lt;NAME&gt; &lt;- function(&lt;ARGUMENTS&gt;){ &lt;ACTIONS&gt; return(&lt;OUTPUT&gt;) } … where NAME is what we want to name the function; ARGUMENTS are the variables in the code that get “tweaked”; ACTIONS are the lines of code we want the function to perform (which includes our ARGUMENTS); and the OUTPUT is the object we want as the final outcome of running the function. For parkwide_visitation(), we will use our upstream code as the basis for our function, but with a few minor yet extremely important tweaks: parkwide_visitation &lt;- function(year){ # pull in the data raw_data &lt;- httr::GET(url = # parse out year so that it can be chosen with the &quot;year&quot; argument, using paste0() paste0(&quot;https://irmaservices.nps.gov/v3/rest/stats/total/&quot;, year)) # convert content to text extracted_data &lt;- httr::content(raw_data, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) # parse text from JSON to data frame final_data &lt;- jsonlite::fromJSON(extracted_data) return(final_data) } In the above function, our first object, raw_data, now changes based on how we define our year argument. We accomplish this through paste0(), which takes listed objects, transforms them into characters (if they aren’t already), and concatenates them into a single character string. For example: my_sentence &lt;- &quot;I need at least&quot; my_other_sentence &lt;- &quot;pints of ice cream a day&quot; paste0(my_sentence, &quot; &quot;, 08, &quot; &quot;, my_other_sentence, &quot;!&quot;) ## [1] &quot;I need at least 8 pints of ice cream a day!&quot; So, if we make year = 2021 in our parkwide_visitation() function, the year object becomes the number 2021, which makes the paste0() output “https://irmaservices.nps.gov/v3/rest/stats/total/2021”, which subsequently pulls data for 2021. In other words, we can now pull visitation data for any year with just one line of code! pull_2018 &lt;- parkwide_visitation(year = 2018) pull_1980 &lt;- parkwide_visitation(year = 1980) pull_1992 &lt;- parkwide_visitation(year = 1992) # ... and so on! 1.4.1 Exercise #3 Create a function called unit_visitation() that pulls park-specific visitation data for any park, across any time frame. For a list of all park codes, download this spreadsheet. (Hint 1: functions can have multiple arguments. Hint 2: what’s the difference between 05 and \"05\"?) unit_visitation &lt;- function(unitCodes, startMonth, startYear, endMonth, endYear){ raw_data &lt;- httr::GET(url = paste0(&quot;https://irmaservices.nps.gov/v3/rest/stats/visitation?unitCodes=&quot;,unitCodes, &quot;&amp;startMonth=&quot;,startMonth,&quot;&amp;startYear=&quot;,startYear,&quot;&amp;endMonth=&quot;, endMonth, &quot;&amp;endYear=&quot;,endYear)) extracted_data &lt;- httr::content(raw_data, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) final_data &lt;- jsonlite::fromJSON(extracted_data) return(final_data) } 1.4.2 Exercise #4 Using unit_visitation(), pull in visitation data for Rocky Mountain National Park (ROMO), Everglades National Park (EVER), and Theodore Roosevelt National Park (THRO) from 1990 through 2021. RomoData &lt;- unit_visitation(&quot;ROMO&quot;, 01, 1990, 12, 2021) EverData &lt;- unit_visitation(&quot;EVER&quot;, 01, 1990, 12, 2021) ThroData &lt;- unit_visitation(&quot;THRO&quot;, 01, 1990, 12, 2021) 1.5 Function Defaults Look at the code that you just wrote; writing out all of those unchanging date arguments still feels repetitive, right? When developing functions, there is an option for setting default values for arguments so that you don’t necessarily have to write all of them out every time you run it in the future. But, the option still exists within the function to make changes when necessary. For example, let’s tweak our parkwide_visitaion() function to have the default year be 2021: parkwide_visitation &lt;- function(year = &quot;2021&quot;) { raw_data &lt;- httr::GET(url = paste0(&quot;https://irmaservices.nps.gov/v3/rest/stats/total/&quot;, year)) # convert content to text extracted_data &lt;- httr::content(raw_data, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) # parse text from JSON to data frame final_data &lt;- jsonlite::fromJSON(extracted_data) return(final_data) } parkwide_visitation() ## Month NonRecreationVisitors RecreationVisitors UnitCode UnitName Year ## 1 1 11632614 11978413 NA NA 2021 ## 2 2 11082899 11692967 NA NA 2021 ## 3 3 12981524 18370611 NA NA 2021 ## 4 4 12857567 22155245 NA NA 2021 ## 5 5 13250575 27963739 NA NA 2021 ## 6 6 13789961 36122392 NA NA 2021 ## 7 7 14734920 41329530 NA NA 2021 ## 8 8 14280304 35380986 NA NA 2021 ## 9 9 13382939 30204635 NA NA 2021 ## 10 10 13882165 26961779 NA NA 2021 ## 11 11 13192146 18903397 NA NA 2021 ## 12 12 13007065 16051712 NA NA 2021 Because the default year is 2021, you don’t have to write it out explicitly in the function (so long as that’s the year you’re interested in). But, you still have the option of changing the year to something else: parkwide_visitation(year = &quot;1992&quot;) ## Month NonRecreationVisitors RecreationVisitors UnitCode UnitName Year ## 1 1 6209285 10940618 NA NA 1992 ## 2 2 6010027 11931340 NA NA 1992 ## 3 3 6756902 15369139 NA NA 1992 ## 4 4 7255782 21458739 NA NA 1992 ## 5 5 7690763 26648530 NA NA 1992 ## 6 6 7593227 33284625 NA NA 1992 ## 7 7 8438755 41099305 NA NA 1992 ## 8 8 8056823 38625804 NA NA 1992 ## 9 9 7329755 26438266 NA NA 1992 ## 10 10 7105574 23616057 NA NA 1992 ## 11 11 6507805 14338165 NA NA 1992 ## 12 12 6702698 10943961 NA NA 1992 1.5.1 Exercise #5 Default our unit_visitation() function’s arguments related to the starting and ending months to January and December, respectively. This way, we are automatically pulling in data for entire years. Rerun the function for ROMO, EVER, and THRO for the 1980-2021 time period to make sure it works properly. unit_visitation2 &lt;- function(unitCodes, startMonth = &quot;01&quot;, startYear, endMonth = &quot;12&quot;, endYear){ raw_data &lt;- httr::GET(url = paste0(&quot;https://irmaservices.nps.gov/v3/rest/stats/visitation?unitCodes=&quot;,unitCodes, &quot;&amp;startMonth=&quot;,startMonth,&quot;&amp;startYear=&quot;,startYear,&quot;&amp;endMonth=&quot;, endMonth, &quot;&amp;endYear=&quot;,endYear)) extracted_data &lt;- httr::content(raw_data, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) final_data &lt;- jsonlite::fromJSON(extracted_data) return(final_data) } ROMONew &lt;- unit_visitation2(&quot;ROMO&quot;, startYear = 1980, endYear = 2021) EVERNew &lt;- unit_visitation2(&quot;EVER&quot;, startYear = 1980, endYear = 2021) THRONew &lt;- unit_visitation2(&quot;THRO&quot;, startYear = 1980, endYear = 2021) 1.6 Iterations At this point, we now know how to develop functions so that we do not have to keep writing out redundant steps in a workflow. However, in that last exercise, you can see that we are still writing out redundant code; we are performing the exact same function on each of our three park units. Another tool for reducing redundancy is iteration, which allows you to do the same thing on multiple inputs. Iteration can happen across different objects, different rows, different data frames, the list goes on and on! 1.7 For loops A for loop is base R’s iteration tool that executes code across a vector, an array, a list, etc. To save the outcome of each iteration, you must first create a vector to store the outputs in that is sized based on how many objects you want to iterate over. For example, I want to run our parkwide_visitation() function over the last five years: 2017, 2018, 2019, 2020, and 2021. To do that, I will first need to develop a vector listing each year: years &lt;- c(&#39;2017&#39;, &#39;2018&#39;, &#39;2019&#39;, &#39;2020&#39;, &#39;2021&#39;) … and then develop an empty list to store each year’s parkwide_visitation() results (i.e., output) into: output_floop &lt;- vector(&quot;list&quot;, length = length(years)) Now that we have a place to store each year’s function results, we can move forward with the for loop itself: for(i in 1:length(years)){ output_floop[[i]] &lt;- parkwide_visitation(year = years[i]) } … where years[i] tells the for loop to perform parkwide_visitation() on the ith year (think of i as a moving across each year), and output_floop[[i]] directs the for loop to store the results of the ith year’s run into output’s ith list (think of output_floop[[i]] as the location in output_floop that the ith’s results go). We now have a list containing five data frames: one for each year of visitation data: summary(output_floop) ## Length Class Mode ## [1,] 6 data.frame list ## [2,] 6 data.frame list ## [3,] 6 data.frame list ## [4,] 6 data.frame list ## [5,] 6 data.frame list Because each year’s output is structured identically, we can confidently combine each year’s data frame into a single data frame using dplyr::bind_rows(): multi_years &lt;- dplyr::bind_rows(output_floop) 1.7.1 Exercise #6 Use a for loop to run unit_visitation() with arguments start_year = 1980 and end_year = 2021 across ROMO, EVER, and THRO. Then, create a single data frame containing each park units’ output. (Hint: Your first step will be to create a vector listing each park unit.) parks &lt;- c(&quot;ROMO&quot;, &quot;EVER&quot;, &quot;THRO&quot;) output_floop2 &lt;- vector(&quot;list&quot;, length = length(parks)) 1.8 Mapping The tidyverse’s purrr package has its own iteration function, map(), that is a variation of the for loop. map() takes a vector and applies a single function across it, then automatically stores all of the results into a list. In other words, map() creates an appropriately sized list to store our results in for us. This eliminates the need to create an empty list ahead of time. To create the same output as our previous for loop on parkwide_visitation(), but using map() instead, we would run the following code: output_map &lt;- years %&gt;% map(~ parkwide_visitation(year = .)) … where ~ indicates that we want to perform parkwide_visitation() across all years, and . indicates that we want to use our piped vector, years, as the input to the year argument. As you can see, output_map is identical to output_floop: identical(output_floop, output_map) ## [1] TRUE … which means we should also bind_rows() to get the mapped output into a single data frame: multi_years &lt;- bind_rows(output_map) 1.8.1 Exercise #7 Use map() to run unit_visitation() with arguments start_year = 1980 and end_year = 2021 across ROMO, EVER, and THRO. Then, create a single data frame containing each park units’ output. library(dplyr) library(purrr) output_map_parks &lt;- parks %&gt;% map(~ unit_visitation2(., startYear = 1980, endYear = 2021)) multi_parks &lt;- bind_rows(output_map_parks) "],["data-munging.html", "Chapter 2 Data Munging 2.1 Pulling in necessary packages and data sets 2.2 Exploring our data 2.3 Pivoting 2.4 Joining", " Chapter 2 Data Munging 2.0.1 Lesson Objectives In the last lesson, we learned how to pull data from an API and reduce redundancies in our workflows through functions and iterations. In this lesson we will use the functions in the previous lesson to learn how to manipulate data frames with the tidyverse, and plot elegant time series graphs with the ggplot(), scales and plotly packages. There are five exercises in this lesson that must be completed. 2.1 Pulling in necessary packages and data sets library(tidyverse) library(httr) library(jsonlite) library(plotly) library(scales) Using the parkwide_visitation() function from the last lesson and mapping, let’s pull park-wide visitor data from 1980-2021, and name the final object parkwide. (Code hack: we can use 1980:2021 to create a vector of years so we don’t have to write each year out!) parkwide_visitation &lt;- function(year){ raw_data &lt;- httr::GET(url = paste0(&quot;https://irmaservices.nps.gov/v3/rest/stats/total/&quot;, year)) extracted_data &lt;- httr::content(raw_data, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) final_data &lt;- jsonlite::fromJSON(extracted_data) return(final_data) } years &lt;- (1980:2021) parkwide &lt;- years %&gt;% map(~ parkwide_visitation(year = .)) %&gt;% bind_rows() 2.1.1 Exercise #1 Using the unit_visitation() function from the last lesson and mapping, pull visitor data from 1980-2021 for the following park units: ROMO, ACAD, LAKE, YELL, GRCA, ZION, OLYM, and GRSM. Name the final output units. parks2 &lt;- c(&quot;ROMO&quot;, &quot;ACAD&quot;, &quot;LAKE&quot;, &quot;YELL&quot;, &quot;GRCA&quot;, &quot;ZION&quot;, &quot;OLYM&quot;, &quot;GRSM&quot;) output_2 &lt;- parks2 %&gt;% map(~ unit_visitation2(., startYear = 1980, endYear = 2021)) units &lt;- bind_rows(output_2) 2.2 Exploring our data Look at the data frame structure of parkwide and units; they’re exactly the same! So let’s go ahead and bind those together: visitation &lt;- bind_rows(parkwide, units) … except, the rows in parkwide’s UnitCode and UnitCode columns are empty.  Let’s fix the UnitCode column to list “Parkwide” using mutate() and an ifelse() statement: visitation &lt;- visitation %&gt;% mutate(UnitCode = ifelse(is.na(UnitCode), &quot;Parkwide&quot;, UnitCode)) Think of the above ifelse() operation as: “If the column UnitCode is NA, replace NA with Parkwide. Otherwise, preserve what is already in the UnitCode column.” Now that we have a single data set containing all of the NPS visitation data that we’ve pulled, let’s start exploring it! But first, let’s aggregate the monthly data into annual data using group_by() and summarize(): yearly &lt;- visitation %&gt;% group_by(UnitCode, Year) %&gt;% # we only care about recreational visitors: summarize(RecVisitation = sum(RecreationVisitors)) yearly ## # A tibble: 378 × 3 ## # Groups: UnitCode [9] ## UnitCode Year RecVisitation ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 ACAD 1980 2779666 ## 2 ACAD 1981 2997972 ## 3 ACAD 1982 3572114 ## 4 ACAD 1983 4124639 ## 5 ACAD 1984 3734763 ## 6 ACAD 1985 3745570 ## 7 ACAD 1986 3929054 ## 8 ACAD 1987 4288154 ## 9 ACAD 1988 4502283 ## 10 ACAD 1989 5440952 ## # … with 368 more rows What does visitation data look like through time? First we can try to graph all of the park units together: ggplot(data=yearly)+ geom_point(aes(x = Year, y = RecVisitation, color = UnitCode)) + geom_path(aes(x = Year, y = RecVisitation, color = UnitCode)) + scale_y_continuous(labels = scales::label_scientific()) + theme_bw(base_size=10) … yikes, not surprisingly, parkwide visitation is wayyyy higher than our individual unit’s visitation data, making our graph pretty useless. It might be nice to have each park unit in a graph of its own. We can create individual graphs for each unit using facet_wrap(), and set the y-axes for each plot to \"free_y\": ggplot(data=yearly) + geom_point(aes(x = Year, y = RecVisitation, color = UnitCode)) + geom_path(aes(x = Year, y = RecVisitation, color = UnitCode)) + scale_y_continuous(labels = scales::label_scientific()) + facet_wrap(~UnitCode, scales = &quot;free_y&quot;) + theme_bw(base_size=10) We can also make this plot interactive by feeding it into plotly’s ggplotly() function: plotly::ggplotly( ggplot(data=yearly) + geom_point(aes(x = Year, y = RecVisitation, color = UnitCode)) + geom_path(aes(x = Year, y = RecVisitation, color = UnitCode)) + scale_y_continuous(labels = scales::label_scientific()) + facet_wrap(~UnitCode, scales = &quot;free_y&quot;) + theme_bw(base_size=10) ) 2.2.1 Exercise #2 Create an interactive graph with two separate panes: one showing park-wide visitation, the other showing all the individual park units together. Both panes should have different y-axes. yearly_modified &lt;- yearly yearly_modified$parkwide &lt;- yearly_modified$UnitCode yearly_modified &lt;- yearly_modified %&gt;% mutate(parkwide = ifelse(parkwide == &quot;Parkwide&quot;, &quot;Parkwide&quot;, &quot;Parks&quot;)) plotly::ggplotly( ggplot(data = yearly_modified) + geom_point(aes(x = Year, y = RecVisitation, color = UnitCode)) + geom_path(aes(x = Year, y = RecVisitation, color = UnitCode)) + scale_y_continuous(labels = scales::label_scientific()) + facet_wrap (~parkwide, scales = &quot;free_y&quot;)) It is pretty clear that some park units get orders of magnitude more visitors than others. But just how much of the total park visitation do each of these parks account for from year to year? Here we walk through two methods to tackle this question, pivoting and joining, to get park unit visitation side-by-side with park-wide data. 2.3 Pivoting Currently, our yearly data is considered narrow because we have all of our NPS visitation data in one column, with multiple rows representing the same year. We can make this data wide by using the function pivot_wider() wide_data &lt;- yearly %&gt;% select(Year, UnitCode, RecVisitation) %&gt;% pivot_wider(., names_from = UnitCode, values_from = RecVisitation) … where names_from represents the column with the values you are hoping to spread into new columns, and values_from represents the data you want to fill these new columns with. We can make the data set narrow again by using the function pivot_longer(): narrow_data &lt;- wide_data %&gt;% pivot_longer(cols = -Year, names_to = &quot;Park&quot;, values_to = &quot;RecVisitation&quot;) … where cols are the columns we want to gather into one column (or, the column(s) you DON’T want to gather), while names_to and values_to are the names of the new columns produced from the pivot. 2.3.1 Exercise #3 Using wide_data as the starting point, create an interactive time series plot showing the annual percentage of the total visitation made up by all park units. wide_data_percent &lt;- wide_data %&gt;% mutate(ACAD = (ACAD/Parkwide) * 100) %&gt;% mutate(GRCA = (GRCA/Parkwide) * 100) %&gt;% mutate(GRSM = (GRSM/Parkwide) * 100) %&gt;% mutate(LAKE = (LAKE/Parkwide) * 100) %&gt;% mutate(OLYM = (OLYM/Parkwide) * 100) %&gt;% mutate(ROMO = (ROMO/Parkwide) * 100) %&gt;% mutate(YELL = (YELL/Parkwide) * 100) %&gt;% mutate(ZION = (ZION/Parkwide) * 100) 2.3.1.0.0.1 I tried using a ‘for’ loop to accomplish this, but R disagreed. wide_data_percent = subset(wide_data_percent, select = -(Parkwide)) narrow_data_percent &lt;- wide_data_percent %&gt;% pivot_longer(cols = -Year, names_to = &quot;Park&quot;, values_to = &quot;Percent&quot;) plotly::ggplotly( ggplot(data = narrow_data_percent) + geom_point(aes(x = Year, y = Percent, color = Park)) + geom_path(aes(x = Year, y = Percent, color = Park)) + facet_wrap (~Park, scales = &quot;free_y&quot;)) 2.4 Joining Another way of getting park-wide visitation side-by-side with the park unit data is through the use of joining our original units and parkwide data sets: joined_data &lt;- inner_join(x = units, y = parkwide, by = c(&quot;Year&quot;,&quot;Month&quot;)) … where x and y are the two data sets you want joined, and by indicates the column(s) to match them by. Note: there are several ways of joining data. Explore them with ?`mutate-joins` and ?`filter-joins`. 2.4.1 Exercise #4 Using joined_data as the starting point, create an interactive time series plot showing the annual percentage of the total visitation made up by all park units. This plot should look nearly identical to the previous plot. joined_data &lt;- joined_data %&gt;% mutate(UnitCode.y = &quot;Parkwide&quot;) joined_data &lt;- joined_data %&gt;% rename(UnitCode = UnitCode.x) %&gt;% rename(Parkwide = UnitCode.y) %&gt;% rename(RecreationVisitors = RecreationVisitors.x) %&gt;% rename(NationwideVisitors = RecreationVisitors.y) joined_yearly &lt;- joined_data %&gt;% group_by(UnitCode, Year) %&gt;% summarize(NatVisitors = sum(NationwideVisitors), RecVisitors = sum(RecreationVisitors)) joined_yearly$percentage &lt;- (joined_yearly$RecVisitors/joined_yearly$NatVisitors)*100 plotly::ggplotly( ggplot(data = joined_yearly) + geom_point(aes(x = Year, y = percentage, color = UnitCode)) + geom_path(aes(x = Year, y = percentage, color = UnitCode)) + facet_wrap (~UnitCode, scales = &quot;free_y&quot;)) 2.4.2 Exercise #5 Which park on average has the most visitation? Which park has the least visitation? Base your response on the data starting in 1990, ending in 2021. Defend your answer with numbers! percentages &lt;- wide_data_percent %&gt;% filter(Year &gt;= 1990) colMeans(percentages) ## Year ACAD GRCA GRSM LAKE OLYM ROMO YELL ## 2005.5000000 0.9297319 1.6090454 3.5046491 2.8391493 1.1190075 1.1427806 1.1720715 ## ZION ## 1.0259186 On average, Great Smokey Mountains National Park has the greatest visitation (3.5% of all visits), while Acadia National Park has the least (0.93% of all visits). "],["denouement.html", "Chapter 3 Denouement 3.1 Lesson Objectives: 3.2 Streaflow Datasets 3.3 Exercise #1 3.4 Exercise #2 3.5 Exercise #3 3.6 Exercise #4 3.7 Exercise #5", " Chapter 3 Denouement 3.1 Lesson Objectives: In this lesson you will take all of the skills you have learned up to this point and use them on a completely new set of data. This lesson has five exercises that need to be completed. 3.1.0.1 Necessary packages: library(tidyverse) library(plotly) library(scales) library(httr) library(jsonlite) library(dataRetrieval) library(sf) # for the map library(mapview) # for making the interactive plot 3.2 Streaflow Datasets We are interested in looking at how the Cache la Poudre River’s flow changes as it travels out of the mountainous Poudre Canyon and through Fort Collins. There are four stream flow monitoring sites on the Poudre that we are interested in: two managed by the US Geological Survey (USGS), and two managed by the Colorado Division of Water Resources (CDWR): 3.2.1 USGS dataRetrieval R package To pull data for USGS stream gauges, we can use the dataRetrieval package, which is a USGS-managed set of functions that, much like our functions from Lesson 3.1, pull data from the USGS’s data warehouse using an API. Here we will pull flow data for our USGS stream gauges of interest for the last two water years: # pulls USGS daily (&#39;dv&#39;) stream flow data: usgs &lt;- dataRetrieval::readNWISdv(siteNumbers = c(&quot;06752260&quot;, &quot;06752280&quot;), # USGS site code for the Poudre River at the Lincoln Bridge and the ELC parameterCd = &quot;00060&quot;, # USGS code for stream flow startDate = &quot;2020-10-01&quot;, # YYYY-MM-DD formatting endDate = &quot;2022-09-30&quot;) %&gt;% # YYYY-MM-DD formatting rename(q_cfs = X_00060_00003) %&gt;% # USGS code for stream flow units in cubic feet per second (CFS) mutate(Date = lubridate::ymd(Date), # convert the Date column to &quot;Date&quot; formatting using the `lubridate` package Site = case_when(site_no == &quot;06752260&quot; ~ &quot;Lincoln&quot;, site_no == &quot;06752280&quot; ~ &quot;Boxelder&quot;)) 3.2.2 CDWR’s API Alas, CDWR does NOT have an R package that pulls data from their API, but they do have user-friendly directions on how to develop API calls. Using the “URL generator” steps outlined for their daily surface water time series data set, we can get the last two water years of CFS data for the Poudre at the Canyon mouth (site abbreviation = CLAFTCCO) using the following URL: https://dwr.state.co.us/Rest/GET/api/v2/surfacewater/surfacewatertsday/?format=json&amp;dateFormat=dateOnly&amp;fields=abbrev%2CmeasDate%2Cvalue%2CmeasUnit&amp;encoding=deflate&amp;abbrev=CLAFTCCO&amp;min-measDate=10%2F01%2F2020&amp;max-measDate=09%2F30%2F2022 measure date = month, day, year 3.3 Exercise #1 Using the URL above as the starting point, develop a function that creates a data frame of CDWR daily flow (CFS) data for a selected range of water years, for any site. (HINT: The final product of our API pull is a list with additional metadata about our API pull… how do we index a list to extract the time series flow data?) crdw_data &lt;- function(siteName, startDate, endDate){ # Obtain raw data raw_data &lt;- httr::GET(url = paste0(&quot;https://dwr.state.co.us/Rest/GET/api/v2/surfacewater/surfacewatertsday/?format=json&amp;dateFormat=dateOnly&amp;fields=abbrev%2CmeasDate%2Cvalue%2CmeasUnit&amp;encoding=deflate&amp;abbrev=&quot;, siteName, &quot;&amp;min-measDate=&quot;, startDate, &quot;&amp;max-measDate=&quot;, endDate)) # Extract raw data extracted_data &lt;- httr::content(raw_data, as = &quot;text&quot;, encoding = &quot;UTF-8&quot;) final_data &lt;- jsonlite::fromJSON(extracted_data) return(final_data) } crdw_data(&quot;CLAFTCCO&quot;, startDate = &quot;10-01-2020&quot;, endDate = &quot;09-30-2022&quot;) ## $PageNumber ## [1] 1 ## ## $PageCount ## [1] 1 ## ## $ResultCount ## [1] 730 ## ## $ResultDateTime ## [1] &quot;2023-03-01&quot; ## ## $ResultList ## abbrev measDate value measUnit ## 1 CLAFTCCO 2020-10-01 42 cfs ## 2 CLAFTCCO 2020-10-02 36 cfs ## 3 CLAFTCCO 2020-10-03 34 cfs ## 4 CLAFTCCO 2020-10-04 32 cfs ## 5 CLAFTCCO 2020-10-05 35 cfs ## 6 CLAFTCCO 2020-10-06 30 cfs ## 7 CLAFTCCO 2020-10-07 30 cfs ## 8 CLAFTCCO 2020-10-08 34 cfs ## 9 CLAFTCCO 2020-10-09 34 cfs ## 10 CLAFTCCO 2020-10-10 27 cfs ## 11 CLAFTCCO 2020-10-11 21 cfs ## 12 CLAFTCCO 2020-10-12 29 cfs ## 13 CLAFTCCO 2020-10-13 26 cfs ## 14 CLAFTCCO 2020-10-14 43 cfs ## 15 CLAFTCCO 2020-10-15 39 cfs ## 16 CLAFTCCO 2020-10-16 44 cfs ## 17 CLAFTCCO 2020-10-17 39 cfs ## 18 CLAFTCCO 2020-10-18 45 cfs ## 19 CLAFTCCO 2020-10-19 46 cfs ## 20 CLAFTCCO 2020-10-20 39 cfs ## 21 CLAFTCCO 2020-10-21 36 cfs ## 22 CLAFTCCO 2020-10-22 46 cfs ## 23 CLAFTCCO 2020-10-23 65 cfs ## 24 CLAFTCCO 2020-10-24 72 cfs ## 25 CLAFTCCO 2020-10-25 60 cfs ## 26 CLAFTCCO 2020-10-26 65 cfs ## 27 CLAFTCCO 2020-10-27 70 cfs ## 28 CLAFTCCO 2020-10-28 69 cfs ## 29 CLAFTCCO 2020-10-29 89 cfs ## 30 CLAFTCCO 2020-10-30 82 cfs ## 31 CLAFTCCO 2020-10-31 74 cfs ## 32 CLAFTCCO 2020-11-01 56 cfs ## 33 CLAFTCCO 2020-11-02 52 cfs ## 34 CLAFTCCO 2020-11-03 44 cfs ## 35 CLAFTCCO 2020-11-04 55 cfs ## 36 CLAFTCCO 2020-11-05 72 cfs ## 37 CLAFTCCO 2020-11-06 86 cfs ## 38 CLAFTCCO 2020-11-07 78 cfs ## 39 CLAFTCCO 2020-11-08 72 cfs ## 40 CLAFTCCO 2020-11-09 65 cfs ## 41 CLAFTCCO 2020-11-10 50 cfs ## 42 CLAFTCCO 2020-11-11 35 cfs ## 43 CLAFTCCO 2020-11-12 30 cfs ## 44 CLAFTCCO 2020-11-13 30 cfs ## 45 CLAFTCCO 2020-11-14 30 cfs ## 46 CLAFTCCO 2020-11-15 40 cfs ## 47 CLAFTCCO 2020-11-16 31 cfs ## 48 CLAFTCCO 2020-11-17 45 cfs ## 49 CLAFTCCO 2020-11-18 51 cfs ## 50 CLAFTCCO 2020-11-19 45 cfs ## 51 CLAFTCCO 2020-11-20 42 cfs ## 52 CLAFTCCO 2020-11-21 38 cfs ## 53 CLAFTCCO 2020-11-22 23 cfs ## 54 CLAFTCCO 2020-11-23 12 cfs ## 55 CLAFTCCO 2020-11-24 60 cfs ## 56 CLAFTCCO 2020-11-25 44 cfs ## 57 CLAFTCCO 2020-11-26 30 cfs ## 58 CLAFTCCO 2020-11-27 39 cfs ## 59 CLAFTCCO 2020-11-28 28 cfs ## 60 CLAFTCCO 2020-11-29 25 cfs ## 61 CLAFTCCO 2020-11-30 34 cfs ## 62 CLAFTCCO 2020-12-01 26 cfs ## 63 CLAFTCCO 2020-12-02 25 cfs ## 64 CLAFTCCO 2020-12-03 25 cfs ## 65 CLAFTCCO 2020-12-04 35 cfs ## 66 CLAFTCCO 2020-12-05 30 cfs ## 67 CLAFTCCO 2020-12-06 35 cfs ## 68 CLAFTCCO 2020-12-07 40 cfs ## 69 CLAFTCCO 2020-12-08 40 cfs ## 70 CLAFTCCO 2020-12-09 45 cfs ## 71 CLAFTCCO 2020-12-10 40 cfs ## 72 CLAFTCCO 2020-12-11 35 cfs ## 73 CLAFTCCO 2020-12-12 30 cfs ## 74 CLAFTCCO 2020-12-13 30 cfs ## 75 CLAFTCCO 2020-12-14 35 cfs ## 76 CLAFTCCO 2020-12-15 40 cfs ## 77 CLAFTCCO 2020-12-16 45 cfs ## 78 CLAFTCCO 2020-12-17 45 cfs ## 79 CLAFTCCO 2020-12-18 50 cfs ## 80 CLAFTCCO 2020-12-19 50 cfs ## 81 CLAFTCCO 2020-12-20 60 cfs ## 82 CLAFTCCO 2020-12-21 65 cfs ## 83 CLAFTCCO 2020-12-22 70 cfs ## 84 CLAFTCCO 2020-12-23 60 cfs ## 85 CLAFTCCO 2020-12-24 65 cfs ## 86 CLAFTCCO 2020-12-25 60 cfs ## 87 CLAFTCCO 2020-12-26 65 cfs ## 88 CLAFTCCO 2020-12-27 60 cfs ## 89 CLAFTCCO 2020-12-28 55 cfs ## 90 CLAFTCCO 2020-12-29 50 cfs ## 91 CLAFTCCO 2020-12-30 45 cfs ## 92 CLAFTCCO 2020-12-31 50 cfs ## 93 CLAFTCCO 2021-01-01 50 cfs ## 94 CLAFTCCO 2021-01-02 50 cfs ## 95 CLAFTCCO 2021-01-03 55 cfs ## 96 CLAFTCCO 2021-01-04 50 cfs ## 97 CLAFTCCO 2021-01-05 55 cfs ## 98 CLAFTCCO 2021-01-06 50 cfs ## 99 CLAFTCCO 2021-01-07 45 cfs ## 100 CLAFTCCO 2021-01-08 45 cfs ## 101 CLAFTCCO 2021-01-09 40 cfs ## 102 CLAFTCCO 2021-01-10 35 cfs ## 103 CLAFTCCO 2021-01-11 40 cfs ## 104 CLAFTCCO 2021-01-12 40 cfs ## 105 CLAFTCCO 2021-01-13 50 cfs ## 106 CLAFTCCO 2021-01-14 45 cfs ## 107 CLAFTCCO 2021-01-15 50 cfs ## 108 CLAFTCCO 2021-01-16 50 cfs ## 109 CLAFTCCO 2021-01-17 50 cfs ## 110 CLAFTCCO 2021-01-18 45 cfs ## 111 CLAFTCCO 2021-01-19 40 cfs ## 112 CLAFTCCO 2021-01-20 55 cfs ## 113 CLAFTCCO 2021-01-21 55 cfs ## 114 CLAFTCCO 2021-01-22 50 cfs ## 115 CLAFTCCO 2021-01-23 50 cfs ## 116 CLAFTCCO 2021-01-24 45 cfs ## 117 CLAFTCCO 2021-01-25 50 cfs ## 118 CLAFTCCO 2021-01-26 40 cfs ## 119 CLAFTCCO 2021-01-27 35 cfs ## 120 CLAFTCCO 2021-01-28 40 cfs ## 121 CLAFTCCO 2021-01-29 45 cfs ## 122 CLAFTCCO 2021-01-30 45 cfs ## 123 CLAFTCCO 2021-01-31 40 cfs ## 124 CLAFTCCO 2021-02-01 45 cfs ## 125 CLAFTCCO 2021-02-02 50 cfs ## 126 CLAFTCCO 2021-02-03 55 cfs ## 127 CLAFTCCO 2021-02-04 45 cfs ## 128 CLAFTCCO 2021-02-05 45 cfs ## 129 CLAFTCCO 2021-02-06 40 cfs ## 130 CLAFTCCO 2021-02-07 45 cfs ## 131 CLAFTCCO 2021-02-08 35 cfs ## 132 CLAFTCCO 2021-02-09 35 cfs ## 133 CLAFTCCO 2021-02-10 35 cfs ## 134 CLAFTCCO 2021-02-11 30 cfs ## 135 CLAFTCCO 2021-02-12 25 cfs ## 136 CLAFTCCO 2021-02-13 25 cfs ## 137 CLAFTCCO 2021-02-14 20 cfs ## 138 CLAFTCCO 2021-02-15 25 cfs ## 139 CLAFTCCO 2021-02-16 30 cfs ## 140 CLAFTCCO 2021-02-17 30 cfs ## 141 CLAFTCCO 2021-02-18 30 cfs ## 142 CLAFTCCO 2021-02-19 35 cfs ## 143 CLAFTCCO 2021-02-20 35 cfs ## 144 CLAFTCCO 2021-02-21 40 cfs ## 145 CLAFTCCO 2021-02-22 40 cfs ## 146 CLAFTCCO 2021-02-23 35 cfs ## 147 CLAFTCCO 2021-02-24 30 cfs ## 148 CLAFTCCO 2021-02-25 35 cfs ## 149 CLAFTCCO 2021-02-26 40 cfs ## 150 CLAFTCCO 2021-02-27 40 cfs ## 151 CLAFTCCO 2021-02-28 45 cfs ## 152 CLAFTCCO 2021-03-01 45 cfs ## 153 CLAFTCCO 2021-03-02 50 cfs ## 154 CLAFTCCO 2021-03-03 55 cfs ## 155 CLAFTCCO 2021-03-04 45 cfs ## 156 CLAFTCCO 2021-03-05 50 cfs ## 157 CLAFTCCO 2021-03-06 50 cfs ## 158 CLAFTCCO 2021-03-07 55 cfs ## 159 CLAFTCCO 2021-03-08 50 cfs ## 160 CLAFTCCO 2021-03-09 56 cfs ## 161 CLAFTCCO 2021-03-10 60 cfs ## 162 CLAFTCCO 2021-03-11 47 cfs ## 163 CLAFTCCO 2021-03-12 48 cfs ## 164 CLAFTCCO 2021-03-13 52 cfs ## 165 CLAFTCCO 2021-03-14 68 cfs ## 166 CLAFTCCO 2021-03-15 70 cfs ## 167 CLAFTCCO 2021-03-16 75 cfs ## 168 CLAFTCCO 2021-03-17 75 cfs ## 169 CLAFTCCO 2021-03-18 79 cfs ## 170 CLAFTCCO 2021-03-19 69 cfs ## 171 CLAFTCCO 2021-03-20 76 cfs ## 172 CLAFTCCO 2021-03-21 92 cfs ## 173 CLAFTCCO 2021-03-22 85 cfs ## 174 CLAFTCCO 2021-03-23 95 cfs ## 175 CLAFTCCO 2021-03-24 100 cfs ## 176 CLAFTCCO 2021-03-25 92 cfs ## 177 CLAFTCCO 2021-03-26 86 cfs ## 178 CLAFTCCO 2021-03-27 80 cfs ## 179 CLAFTCCO 2021-03-28 86 cfs ## 180 CLAFTCCO 2021-03-29 110 cfs ## 181 CLAFTCCO 2021-03-30 157 cfs ## 182 CLAFTCCO 2021-03-31 161 cfs ## 183 CLAFTCCO 2021-04-01 97 cfs ## 184 CLAFTCCO 2021-04-02 51 cfs ## 185 CLAFTCCO 2021-04-03 68 cfs ## 186 CLAFTCCO 2021-04-04 97 cfs ## 187 CLAFTCCO 2021-04-05 118 cfs ## 188 CLAFTCCO 2021-04-06 158 cfs ## 189 CLAFTCCO 2021-04-07 130 cfs ## 190 CLAFTCCO 2021-04-08 133 cfs ## 191 CLAFTCCO 2021-04-09 93 cfs ## 192 CLAFTCCO 2021-04-10 67 cfs ## 193 CLAFTCCO 2021-04-11 81 cfs ## 194 CLAFTCCO 2021-04-12 68 cfs ## 195 CLAFTCCO 2021-04-13 67 cfs ## 196 CLAFTCCO 2021-04-14 65 cfs ## 197 CLAFTCCO 2021-04-15 67 cfs ## 198 CLAFTCCO 2021-04-16 79 cfs ## 199 CLAFTCCO 2021-04-17 79 cfs ## 200 CLAFTCCO 2021-04-18 76 cfs ## 201 CLAFTCCO 2021-04-19 83 cfs ## 202 CLAFTCCO 2021-04-20 82 cfs ## 203 CLAFTCCO 2021-04-21 86 cfs ## 204 CLAFTCCO 2021-04-22 162 cfs ## 205 CLAFTCCO 2021-04-23 238 cfs ## 206 CLAFTCCO 2021-04-24 233 cfs ## 207 CLAFTCCO 2021-04-25 260 cfs ## 208 CLAFTCCO 2021-04-26 338 cfs ## 209 CLAFTCCO 2021-04-27 268 cfs ## 210 CLAFTCCO 2021-04-28 414 cfs ## 211 CLAFTCCO 2021-04-29 567 cfs ## 212 CLAFTCCO 2021-04-30 761 cfs ## 213 CLAFTCCO 2021-05-01 1080 cfs ## 214 CLAFTCCO 2021-05-02 1220 cfs ## 215 CLAFTCCO 2021-05-03 1420 cfs ## 216 CLAFTCCO 2021-05-04 1450 cfs ## 217 CLAFTCCO 2021-05-05 1450 cfs ## 218 CLAFTCCO 2021-05-06 1350 cfs ## 219 CLAFTCCO 2021-05-07 1370 cfs ## 220 CLAFTCCO 2021-05-08 1490 cfs ## 221 CLAFTCCO 2021-05-09 1590 cfs ## 222 CLAFTCCO 2021-05-10 1370 cfs ## 223 CLAFTCCO 2021-05-11 1240 cfs ## 224 CLAFTCCO 2021-05-12 1130 cfs ## 225 CLAFTCCO 2021-05-13 1140 cfs ## 226 CLAFTCCO 2021-05-14 1040 cfs ## 227 CLAFTCCO 2021-05-15 1160 cfs ## 228 CLAFTCCO 2021-05-16 1260 cfs ## 229 CLAFTCCO 2021-05-17 1380 cfs ## 230 CLAFTCCO 2021-05-18 1440 cfs ## 231 CLAFTCCO 2021-05-19 1820 cfs ## 232 CLAFTCCO 2021-05-20 1650 cfs ## 233 CLAFTCCO 2021-05-21 1850 cfs ## 234 CLAFTCCO 2021-05-22 1780 cfs ## 235 CLAFTCCO 2021-05-23 2660 cfs ## 236 CLAFTCCO 2021-05-24 2180 cfs ## 237 CLAFTCCO 2021-05-25 1920 cfs ## 238 CLAFTCCO 2021-05-26 1870 cfs ## 239 CLAFTCCO 2021-05-27 1700 cfs ## 240 CLAFTCCO 2021-05-28 1730 cfs ## 241 CLAFTCCO 2021-05-29 1680 cfs ## 242 CLAFTCCO 2021-05-30 1630 cfs ## 243 CLAFTCCO 2021-05-31 1530 cfs ## 244 CLAFTCCO 2021-06-01 1560 cfs ## 245 CLAFTCCO 2021-06-02 1510 cfs ## 246 CLAFTCCO 2021-06-03 1550 cfs ## 247 CLAFTCCO 2021-06-04 1760 cfs ## 248 CLAFTCCO 2021-06-05 2020 cfs ## 249 CLAFTCCO 2021-06-06 2170 cfs ## 250 CLAFTCCO 2021-06-07 2350 cfs ## [ reached &#39;max&#39; / getOption(&quot;max.print&quot;) -- omitted 480 rows ] 3.4 Exercise #2 Map over the function you developed in Exercise #1 to pull flow data for CLAFTCCO and CLARIVCO for the 2021 and 2022 water years. sites &lt;- c(&quot;CLAFTCCO&quot;, &quot;CLARIVCO&quot;) output_map &lt;- sites %&gt;% map(~ crdw_data(siteName = ., startDate = &quot;10-01-2020&quot;, endDate = &quot;09-30-2022&quot;)) multi_sites &lt;- bind_rows(output_map) multi_site_results &lt;- data.frame(multi_sites$ResultList) 3.5 Exercise #3 Join our USGS and CDWR data frames together (bind_rows(), perhaps?), then create an interactive ggplot of discharge (in CFS) through time displaying all four of our monitoring sites. Be sure all axes and labels are clear. multi_site_results &lt;- multi_site_results %&gt;% rename(Date = measDate) %&gt;% rename(Site = abbrev) %&gt;% rename(q_cfs = value) wide_multi_sites &lt;- multi_site_results %&gt;% select(Site, Date, q_cfs) %&gt;% pivot_wider(., names_from = Site, values_from = q_cfs) wide_usgs &lt;- usgs %&gt;% select(Site, Date, q_cfs) %&gt;% pivot_wider(., names_from = Site, values_from = q_cfs) library(lubridate) wide_multi_sites$Date &lt;- as_date(wide_multi_sites$Date) joined_site_data &lt;- inner_join(x = wide_multi_sites, y = wide_usgs, by = &quot;Date&quot;) narrow_site_data &lt;- joined_site_data %&gt;% pivot_longer(cols = -Date, names_to = &quot;Site&quot;, values_to = &quot;flow&quot;) plotly::ggplotly( ggplot(data = narrow_site_data) + geom_point(aes(x = Date, y = flow, color = Site)) + geom_path(aes(x = Date, y = flow, color = Site)) + facet_wrap (~Site, scales = &quot;free_y&quot;)) 3.6 Exercise #4 Create an interactive plot of the daily difference in discharge between the Cache la Poudre River at the canyon mouth and each of the sites downstream. Make sure your plot axes are clear. New columns with difference between CLAFTCCO and the downstream sites joined_data_difference &lt;- joined_site_data %&gt;% mutate(Lincoln = (CLAFTCCO - Lincoln)) %&gt;% mutate(Boxelder = (CLAFTCCO - Boxelder)) %&gt;% mutate(CLARIVCO = (CLAFTCCO - CLARIVCO)) joined_data_difference = subset(joined_data_difference, select = -(CLAFTCCO)) narrow_difference &lt;- joined_data_difference %&gt;% pivot_longer(cols = -Date, names_to = &quot;Site&quot;, values_to = &quot;Difference&quot;) plotly::ggplotly( ggplot(data = narrow_difference) + geom_point(aes(x = Date, y = Difference, color = Site)) + geom_path(aes(x = Date, y = Difference, color = Site)) + facet_wrap (~Site, scales = &quot;free_y&quot;) + labs(title = &quot;Difference in Flow between Poudre Canyon Mouth and Downstream Sites&quot;) + ylab(&quot;Difference (cfs)&quot;)) 3.7 Exercise #5 For each of our downstream locations, calculate how many days the canyon mouth had LOWER flow. Is this what you expected? Why or why not? table(joined_data_difference$Lincoln&lt;0) ## ## FALSE TRUE ## 669 61 table(joined_data_difference$Boxelder&lt;0) ## ## FALSE TRUE ## 722 8 table(joined_data_difference$CLARIVCO&lt;0) ## ## FALSE TRUE ## 649 38 I did not expect the canyon mouth to have lower flow than Lincoln Bridge on only 59 days, the Environmental Learning Center on 8 days, and CLARIVCO on 38 days. Typically, the flow of a river increases from upstream to downstream. However, this makes sense. In our semi-arid climate, the demand for water is extremely high. I am not surprised that the majority of LOWER dates occurred during October 2020, when the Cameron Peak Fire made water from the Cache la Poudre river unsafe for consumption. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
